{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.7\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-master-4.newprolab.com:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f1cd51d6588>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 2 pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import Row\n",
    "import json\n",
    "\n",
    "conf = SparkConf()\n",
    "\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .config(conf=conf)\n",
    "         .appName(\"test\")\n",
    "         .getOrCreate())\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выгрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, DoubleType, StringType, IntegerType, ArrayType\n",
    "from pyspark.ml.linalg import VectorUDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"id\", StringType()),\n",
    "    StructField(\"desc\", StringType()),\n",
    "    StructField(\"cat\", StringType()),\n",
    "    StructField(\"name\", StringType()),\n",
    "    StructField(\"lang\", StringType()),\n",
    "    StructField(\"provider\", StringType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses = spark.read.json('/labs/slaba02/DO_record_per_line.json', schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- desc: string (nullable = true)\n",
      " |-- cat: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- provider: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "courses.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------------------------------------------------------------------------------+\n",
      "|id   |lang|desc                                                                          |\n",
      "+-----+----+------------------------------------------------------------------------------+\n",
      "|23126|en  |Compass - powerful SASS library that makes your life easier                   |\n",
      "|21617|en  |Preparing for the AP* Computer Science A Exam — Part 2                        |\n",
      "|16627|es  |Aprende Excel: Nivel Intermedio by Alfonso Rinsche                            |\n",
      "|11556|es  |Aprendizaje Colaborativo by UNID Universidad Interamericana para el Desarrollo|\n",
      "|16704|ru  |Программирование на Lazarus                                                   |\n",
      "|13702|ru  |Математическая экономика                                                      |\n",
      "+-----+----+------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_courses = [[23126, u'en', u'Compass - powerful SASS library that makes your life easier'], [21617, u'en', u'Preparing for the AP* Computer Science A Exam \\u2014 Part 2'], [16627, u'es', u'Aprende Excel: Nivel Intermedio by Alfonso Rinsche'], [11556, u'es', u'Aprendizaje Colaborativo by UNID Universidad Interamericana para el Desarrollo'], [16704, u'ru', u'\\u041f\\u0440\\u043e\\u0433\\u0440\\u0430\\u043c\\u043c\\u0438\\u0440\\u043e\\u0432\\u0430\\u043d\\u0438\\u0435 \\u043d\\u0430 Lazarus'], [13702, u'ru', u'\\u041c\\u0430\\u0442\\u0435\\u043c\\u0430\\u0442\\u0438\\u0447\\u0435\\u0441\\u043a\\u0430\\u044f \\u044d\\u043a\\u043e\\u043d\\u043e\\u043c\\u0438\\u043a\\u0430']]\n",
    "target_df = spark.createDataFrame(target_courses, schema=courses['id', 'lang', 'desc'].schema)\n",
    "target_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['by', 'el', 'a', 'the', 'a', 'to', 'на', 'that', 'for']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Установка необходимых ML библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import VectorUDT, DenseVector\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF, CountVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка текстовых описаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(u'[\\w\\d]{2,}', re.U)\n",
    "\n",
    "# @f.pandas_udf(StringType())\n",
    "def word_tokenizer(text):\n",
    "    text = \" \".join(regex.findall(str(text).lower())).split(\" \")\n",
    "    return [word for word in text if word not in stop_words]\n",
    "\n",
    "udf_word_tokenizer = f.udf(word_tokenizer, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# courses = courses.withColumn('desc', f.concat(courses.desc, courses.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = target_df.withColumn('desc', udf_word_tokenizer('desc'))\n",
    "courses = courses.withColumn('desc', udf_word_tokenizer('desc'))\n",
    "\n",
    "target_df_joined = target_df.join(courses.select(f.col('id'), f.col('lang').alias('lang_2') , f.col('desc').alias('desc_2'))\n",
    "                                  , on='id')\n",
    "target_df = target_df_joined.select('id', 'lang', f.col('desc_2').alias('desc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = HashingTF(numFeatures=10000, inputCol='desc', outputCol='features_tf')\n",
    "idf = IDF(inputCol='features_tf', outputCol='features_tfidf', minDocFreq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- desc: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- cat: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- provider: string (nullable = true)\n",
      " |-- features_tf: vector (nullable = true)\n",
      " |-- features_tfidf: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf_courses = tf.transform(courses)\n",
    "idf_courses = idf.fit(tf_courses)\n",
    "tfidf_courses = idf_courses.transform(tf_courses)\n",
    "tfidf_courses.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- desc: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- features_tf: vector (nullable = true)\n",
      " |-- features_tfidf: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf_target = tf.transform(target_df)\n",
    "tfidf_target = idf_courses.transform(tf_target)\n",
    "tfidf_target.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+--------------------+--------------------+--------------------+\n",
      "|   id|lang|                desc|         features_tf|      features_tfidf|\n",
      "+-----+----+--------------------+--------------------+--------------------+\n",
      "|23126|  en|[improve, your, s...|(10000,[87,91,128...|(10000,[87,91,128...|\n",
      "|21617|  en|[an, introduction...|(10000,[17,128,16...|(10000,[17,128,16...|\n",
      "|16627|  es|[hazte, más, empl...|(10000,[55,76,192...|(10000,[55,76,192...|\n",
      "|11556|  es|[la, transformaci...|(10000,[249,522,5...|(10000,[249,522,5...|\n",
      "|16704|  ru|[курсе, рассматри...|(10000,[381,1144,...|(10000,[381,1144,...|\n",
      "|13702|  ru|[математическая, ...|(10000,[310,942,2...|(10000,[310,942,2...|\n",
      "+-----+----+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_target.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(target, u):\n",
    "    return float(target.dot(u) / (target.norm(2) * u.norm(2)))\n",
    "\n",
    "udf_cos_sim = f.udf(cos_sim, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, lang: string, desc: array<string>, features_tf: vector, features_tfidf: vector]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_target = tfidf_target.select(f.col(\"id\").alias('target_id'), \n",
    "                                   f.col('lang'), \n",
    "                                   f.col('features_tfidf').alias('target_features'),\n",
    "                                   )\n",
    "tfidf_courses = tfidf_courses.select(f.col(\"id\"), \n",
    "                                   f.col('lang'), \n",
    "                                   f.col('features_tfidf'),\n",
    "                                    f.col('name'))\n",
    "joined = tfidf_target.join(tfidf_courses, on='lang', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+--------------------+-----+--------------------+--------------------+\n",
      "|lang|target_id|     target_features|   id|      features_tfidf|                name|\n",
      "+----+---------+--------------------+-----+--------------------+--------------------+\n",
      "|  en|    23126|(10000,[87,91,128...|16308|(10000,[505,1387,...|Up and Running wi...|\n",
      "|  en|    23126|(10000,[87,91,128...|16309|(10000,[128,201,9...|Up and Running wi...|\n",
      "|  en|    23126|(10000,[87,91,128...|16310|(10000,[505,706,1...|Up and Running wi...|\n",
      "|  en|    23126|(10000,[87,91,128...|16311|(10000,[281,1089,...|Up and Running wi...|\n",
      "|  en|    23126|(10000,[87,91,128...|16312|(10000,[1239,1445...|Up and Running wi...|\n",
      "+----+---------+--------------------+-----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = joined.select('target_id', 'id', 'lang', 'name', (udf_cos_sim('target_features', \"features_tfidf\")).alias('similarity'))\n",
    "result_df = result_df.dropna().cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+----+--------------------+--------------------+\n",
      "|target_id|   id|lang|                name|          similarity|\n",
      "+---------+-----+----+--------------------+--------------------+\n",
      "|    23126|16308|  en|Up and Running wi...|0.010768667796949046|\n",
      "|    23126|16309|  en|Up and Running wi...|0.004397617582649494|\n",
      "|    23126|16310|  en|Up and Running wi...|0.018393138569793823|\n",
      "|    23126|16311|  en|Up and Running wi...| 0.00758436221389505|\n",
      "|    23126|16312|  en|Up and Running wi...|5.733964272051451E-4|\n",
      "+---------+-----+----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = result_df.select('target_id').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dict()\n",
    "for course in range(6):\n",
    "    result[targets[course]['target_id']] = result_df[(result_df['target_id'] == targets[course]['target_id']) & (result_df['id'] != targets[course]['target_id'])] \\\n",
    "                                            .dropDuplicates(['name']) \\\n",
    "                                            .select('id', 'similarity') \\\n",
    "                                            .sort(result_df.similarity.desc(), result_df.id.asc(), result_df.name.asc()).limit(10).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_f = dict()\n",
    "for key in result.keys():\n",
    "    result_f[key] = list()\n",
    "    for el in range(10):\n",
    "        \n",
    "        result_f[key].append(result[key][el]['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lab02.json', 'w') as fp:\n",
    "    json.dump(result_f, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
